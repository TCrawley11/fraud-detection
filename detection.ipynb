{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae46ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to dataset files: /home/tygo/.cache/kagglehub/datasets/mlg-ulb/creditcardfraud/versions/3\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scikit-learn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# download the dataset\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "\n",
    "print(\"path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1eb1490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
       "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
       "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
       "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Trying to get a better sense of the data\n",
    "csv_path = path + '/creditcard.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a3979e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.175161e-15</td>\n",
       "      <td>3.384974e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.094852e-15</td>\n",
       "      <td>1.021879e-15</td>\n",
       "      <td>1.494498e-15</td>\n",
       "      <td>-5.620335e-16</td>\n",
       "      <td>1.149614e-16</td>\n",
       "      <td>-2.414189e-15</td>\n",
       "      <td>2.238554e-15</td>\n",
       "      <td>1.724421e-15</td>\n",
       "      <td>-1.245415e-15</td>\n",
       "      <td>8.238900e-16</td>\n",
       "      <td>1.213481e-15</td>\n",
       "      <td>4.866699e-15</td>\n",
       "      <td>1.436219e-15</td>\n",
       "      <td>-3.768179e-16</td>\n",
       "      <td>9.707851e-16</td>\n",
       "      <td>1.036249e-15</td>\n",
       "      <td>6.418678e-16</td>\n",
       "      <td>1.628620e-16</td>\n",
       "      <td>-3.576577e-16</td>\n",
       "      <td>2.618565e-16</td>\n",
       "      <td>4.473914e-15</td>\n",
       "      <td>5.109395e-16</td>\n",
       "      <td>1.686100e-15</td>\n",
       "      <td>-3.661401e-16</td>\n",
       "      <td>-1.227452e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1  ...         Amount          Class\n",
       "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
       "mean    94813.859575  1.175161e-15  ...      88.349619       0.001727\n",
       "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
       "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
       "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
       "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
       "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
       "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dd64657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and test, use SMOTE since the dataset is imbalanced\n",
    "\n",
    "X = df.iloc[:, :30] # all rows, first 30 columns\n",
    "y = df.iloc[:, 30]  # all rows, last column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "097daa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tygo/Code/fraud-detection/.venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9971325913181888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model and fit it on the training data\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rc = RidgeClassifier(alpha=1, solver='saga') # decided on saga for the large number of features and samples\n",
    "clf = rc.fit(X_train_res, y_train_res)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405024a",
   "metadata": {},
   "source": [
    "So, this score is good, but too good to be true without much work. I used SMOTE to balance the dataset, which was a good choice I believe, but the choice of model could be slightly better. Models like random forest, XGBoost, or a NN may capture non-linear patterns better. Additionally, accuracy is not the only measure of performance, especially on such an imbalanced dataset. \n",
    "\n",
    "The next step is to use better evaluation metrics. Going to fit two other models, and display more informative metrics like precision, recall, and F1-score for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ba1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.35      0.76      0.48       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.67      0.88      0.74     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34dafe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85087,   209],\n",
       "       [   36,   111]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aa2de",
   "metadata": {},
   "source": [
    "Looking at the results, the model actually fails about 25% of the fraudulent cases. With only a 35% precision, which could be costly in something fragile like fraud detection. \n",
    "\n",
    "Trying a random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cde8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995201479348805"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c98904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.90      0.82      0.85       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.91      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rf_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c4250",
   "metadata": {},
   "source": [
    "Pretty good results,  can see that 90% of cases that were classified as fraud were indeed fraudulent cases, but a slightly problematic recall of 82%. Now I want to try a neural net trained on the SMOTE dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d70f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to use tf-nightly since this venv is on python 3.13\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df1e9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tygo/Code/fraud-detection/.venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-12 19:30:12.821342: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "n_inputs = X_train_res.shape[1]\n",
    "\n",
    "smote_model = Sequential([\n",
    "    Dense(128, input_shape=(n_inputs,), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b421cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5011 - val_accuracy: 0.7530 - val_loss: 0.6894\n",
      "Epoch 2/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.2960 - val_accuracy: 0.9801 - val_loss: 0.0411\n",
      "Epoch 3/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.2760 - val_accuracy: 0.9881 - val_loss: 0.0303\n",
      "Epoch 4/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.2743 - val_accuracy: 0.8664 - val_loss: 0.3254\n",
      "Epoch 5/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.2649 - val_accuracy: 0.9563 - val_loss: 0.0740\n",
      "Epoch 6/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.2600 - val_accuracy: 0.9494 - val_loss: 0.0838\n",
      "Epoch 7/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.2596 - val_accuracy: 0.9506 - val_loss: 0.0770\n",
      "Epoch 8/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.2563 - val_accuracy: 0.9673 - val_loss: 0.0599\n",
      "Epoch 9/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2557 - val_accuracy: 0.9319 - val_loss: 0.1279\n",
      "Epoch 10/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.2584 - val_accuracy: 0.8848 - val_loss: 0.2762\n",
      "Epoch 11/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.2591 - val_accuracy: 0.9087 - val_loss: 0.1727\n",
      "Epoch 12/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.2578 - val_accuracy: 0.9562 - val_loss: 0.0830\n",
      "Epoch 13/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2532 - val_accuracy: 0.9806 - val_loss: 0.0424\n",
      "Epoch 14/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.2515 - val_accuracy: 0.8676 - val_loss: 0.3718\n",
      "Epoch 15/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.2468 - val_accuracy: 0.9406 - val_loss: 0.1145\n",
      "Epoch 16/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8723 - loss: 0.2490 - val_accuracy: 0.8989 - val_loss: 0.2124\n",
      "Epoch 17/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2498 - val_accuracy: 0.8852 - val_loss: 0.2929\n",
      "Epoch 18/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.2437 - val_accuracy: 0.9227 - val_loss: 0.1770\n",
      "Epoch 19/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.2518 - val_accuracy: 0.9318 - val_loss: 0.1412\n",
      "Epoch 20/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.2480 - val_accuracy: 0.9074 - val_loss: 0.1886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f24589297f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "smote_model.fit(X_train_res, y_train_res,\n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                validation_split=0.2,\n",
    "                shuffle=True,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9f5a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = smote_model.predict(X_test, verbose=1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf9dfab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.67      0.83      0.74       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.84      0.91      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3b10ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0555 - val_accuracy: 0.9956 - val_loss: 0.0118\n",
      "Epoch 2/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0205 - val_accuracy: 0.9992 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0151 - val_accuracy: 0.9986 - val_loss: 0.0048\n",
      "Epoch 4/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.9991 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 0.9999 - val_loss: 9.2155e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9996 - val_loss: 0.0020\n",
      "Epoch 7/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 7.3611e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 5.3481e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 6.2103e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.9994 - val_loss: 0.0020\n",
      "Epoch 13/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 14/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9999 - val_loss: 9.9389e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 0.9999 - val_loss: 7.1112e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 5.5012e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 7.8022e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9999 - val_loss: 5.7211e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 2.3295e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 2.9981e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2459716210>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to scale the data to improve performance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "smote_model.fit(X_train_res_scaled, y_train_res, \n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1766156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.53      0.84      0.65       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.76      0.92      0.82     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_scaled = smote_model.predict(X_test_scaled, verbose=1)\n",
    "y_pred = (y_pred_prob_scaled > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65c85879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 5.5418e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9998 - val_loss: 7.3029e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.9078e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.0713e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 4.5380e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 3.9350e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 2.8346e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.3098e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 2.5097e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 1.9194e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 8.6127e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.0250e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 1.5042e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 3.3615e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 8.3685e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 1.3335e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 3.5007e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 3.3301e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.5731e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 8.5993e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f24589375c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now try balancing the loss to penalize false negatives\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_res), y=y_train_res)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "smote_model.fit(X_train_res_scaled, y_train_res,\n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                class_weight=class_weights_dict,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e21df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.82      0.82      0.82       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.91      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = smote_model.predict(X_test_scaled, verbose=1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fbe8c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "smote_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(smote_matrix, display_labels=['No Fraud', 'Fraud'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
