{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae46ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tygo/Code/fraud-detection/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to dataset files: /home/tygo/.cache/kagglehub/datasets/mlg-ulb/creditcardfraud/versions/3\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scikit-learn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# download the dataset\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "\n",
    "print(\"path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1eb1490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Trying to get a better sense of the data\n",
    "csv_path = path + '/creditcard.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a3979e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.175161e-15</td>\n",
       "      <td>3.384974e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.094852e-15</td>\n",
       "      <td>1.021879e-15</td>\n",
       "      <td>1.494498e-15</td>\n",
       "      <td>-5.620335e-16</td>\n",
       "      <td>1.149614e-16</td>\n",
       "      <td>-2.414189e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628620e-16</td>\n",
       "      <td>-3.576577e-16</td>\n",
       "      <td>2.618565e-16</td>\n",
       "      <td>4.473914e-15</td>\n",
       "      <td>5.109395e-16</td>\n",
       "      <td>1.686100e-15</td>\n",
       "      <td>-3.661401e-16</td>\n",
       "      <td>-1.227452e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.175161e-15  3.384974e-16 -1.379537e-15  2.094852e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.021879e-15  1.494498e-15 -5.620335e-16  1.149614e-16 -2.414189e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.628620e-16 -3.576577e-16  2.618565e-16  4.473914e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.109395e-16  1.686100e-15 -3.661401e-16 -1.227452e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd64657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and test, use SMOTE since the dataset is imbalanced\n",
    "\n",
    "X = df.iloc[:, :30] # all rows, first 30 columns\n",
    "y = df.iloc[:, 30]  # all rows, last column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0\n",
    ")\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097daa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tygo/Code/fraud-detection/.venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9971325913181888"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model and fit it on the training data\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rc = RidgeClassifier(alpha=1, solver='saga') # decided on saga for the large number of features and samples\n",
    "clf = rc.fit(X_train_res, y_train_res)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405024a",
   "metadata": {},
   "source": [
    "So, this score is good, but too good to be true without much work. I used SMOTE to balance the dataset, which was a good choice I believe, but the choice of model could be slightly better. Models like random forest, XGBoost, or a NN may capture non-linear patterns better. Additionally, accuracy is not the only measure of performance, especially on such an imbalanced dataset. \n",
    "\n",
    "The next step is to use better evaluation metrics. Going to fit two other models, and display more informative metrics like precision, recall, and F1-score for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ba1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.35      0.76      0.48       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.67      0.88      0.74     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34dafe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85087,   209],\n",
       "       [   36,   111]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aa2de",
   "metadata": {},
   "source": [
    "Looking at the results, the model actually fails about 25% of the fraudulent cases. With only a 35% precision, which could be costly in something fragile like fraud detection. \n",
    "\n",
    "Trying a random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cde8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995435553526912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_res, y_train_res)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c98904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.90      0.82      0.86       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.91      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rf_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c4250",
   "metadata": {},
   "source": [
    "Pretty good results,  can see that 90% of cases that were classified as fraud were indeed fraudulent cases, but a slightly problematic recall of 82%. Now I want to try a neural net trained on the SMOTE dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to use tf-nightly since this venv is on python 3.13\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df1e9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tygo/Code/fraud-detection/.venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_inputs = X_train_res.shape[1]\n",
    "\n",
    "smote_model = Sequential([\n",
    "    Dense(64, input_shape=(n_inputs, ),activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') # use sigmoid for binary output\n",
    "])\n",
    "smote_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b421cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "smote_model.fit(X_train_res, y_train_res,\n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                validation_split=0.2,\n",
    "                shuffle=True,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9f5a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = smote_model.predict(X_test, verbose=1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf9dfab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.09      0.89      0.16       147\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.54      0.94      0.57     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b10ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.2723 - val_accuracy: 0.9937 - val_loss: 0.0144\n",
      "Epoch 2/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0353 - val_accuracy: 0.9893 - val_loss: 0.0278\n",
      "Epoch 3/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0236 - val_accuracy: 0.9994 - val_loss: 0.0020\n",
      "Epoch 4/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0200 - val_accuracy: 0.9689 - val_loss: 0.0980\n",
      "Epoch 5/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0158 - val_accuracy: 0.9975 - val_loss: 0.0079\n",
      "Epoch 6/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0139 - val_accuracy: 0.9974 - val_loss: 0.0068\n",
      "Epoch 7/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.9989 - val_loss: 0.0042\n",
      "Epoch 8/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.9676 - val_loss: 0.1127\n",
      "Epoch 9/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0091 - val_accuracy: 0.9986 - val_loss: 0.0057\n",
      "Epoch 10/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9996 - val_loss: 0.0022\n",
      "Epoch 11/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 8.3671e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 0.9973 - val_loss: 0.0070\n",
      "Epoch 13/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.9991 - val_loss: 0.0041\n",
      "Epoch 14/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9919 - val_loss: 0.0287\n",
      "Epoch 15/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9984 - val_loss: 0.0053\n",
      "Epoch 16/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9948 - val_loss: 0.0126\n",
      "Epoch 17/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
      "Epoch 18/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9979 - val_loss: 0.0058\n",
      "Epoch 19/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9993 - val_loss: 0.0017\n",
      "Epoch 20/20\n",
      "\u001b[1m9951/9951\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9999 - val_loss: 8.3809e-04\n",
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 985us/step\n"
     ]
    }
   ],
   "source": [
    "# Trying to scale the data to improve performance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "smote_model.fit(X_train_res_scaled, y_train_res, \n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f1766156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.62      0.82      0.71       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.81      0.91      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_scaled = smote_model.predict(X_test_scaled, verbose=1)\n",
    "y_pred = (y_pred_prob_scaled > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "65c85879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 6.2663e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9998 - val_loss: 7.7960e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 3.1092e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 1.8542e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9988 - val_loss: 0.0035\n",
      "Epoch 6/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9976 - val_loss: 0.0067\n",
      "Epoch 7/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.0837e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.0395e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 8.0130e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.9026e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 9.6088e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 2.2266e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9977 - val_loss: 0.0078\n",
      "Epoch 14/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9995 - val_loss: 0.0022\n",
      "Epoch 15/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9992 - val_loss: 0.0021\n",
      "Epoch 16/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 8.3454e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 9.1426e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.7125e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.0973e-04 - val_accuracy: 1.0000 - val_loss: 1.7046e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m4976/4976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 8.3839e-04 - val_accuracy: 1.0000 - val_loss: 3.5183e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe4eb5dfa70>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now try balancing the loss to penalize false negatives\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_res), y=y_train_res)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "smote_model.fit(X_train_res_scaled, y_train_res,\n",
    "                epochs=20,\n",
    "                batch_size=64,\n",
    "                validation_split=0.2,\n",
    "                class_weight=class_weights_dict,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e21df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.09      0.17     85296\n",
      "           1       0.00      0.50      0.00       147\n",
      "\n",
      "    accuracy                           0.09     85443\n",
      "   macro avg       0.50      0.30      0.08     85443\n",
      "weighted avg       0.99      0.09      0.17     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = smote_model.predict(X_test_scaled, verbose=1)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fbe8c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVYBJREFUeJzt3XlcVOX+B/DPDDjsA4oCkogYLpAoiYWTaZkklnVdb1pkqGhXgxJwL0VSE5fccOPmht00l0pLLJQ0NQU1McoNUtPQdNBEGCVhYOb8/uA3J0dcGA4Iw3zer9d5vZxzvs9znkOTfH22IxMEQQARERGRBZLXdgOIiIiIagsTISIiIrJYTISIiIjIYjERIiIiIovFRIiIiIgsFhMhIiIislhMhIiIiMhiWdd2A6givV6Py5cvw8nJCTKZrLabQ0REJhAEATdv3oSnpyfk8prrbyguLoZWq5Vcj0KhgK2tbTW0yDwxEaqDLl++DC8vr9puBhERSXDx4kU0a9asRuouLi6Gj7cj1Fd1kuvy8PDA+fPnLTYZYiJUBzk5OQEA/jjWAkpHjl5S/dSvdUBtN4GoRpShFAfwrfh3eU3QarVQX9Xhj8wWUDpV/feE5qYe3kEXoNVqmQhR3WEYDlM6yiV9wYnqMmtZg9puAlHN+P8XVz2KqQ2OTjI4OlX9Pnpw+gUTISIiIjOlE/TQSXhjqE7QV19jzBQTISIiIjOlhwA9qp4JSSlbX3DchYiIiCwWe4SIiIjMlB56SBnckla6fmAiREREZKZ0ggCdUPXhLSll6wsOjREREZHFYo8QERGRmeJkaemYCBEREZkpPQTomAhJwqExIiIisljsESIiIjJTHBqTjokQERGRmeKqMek4NEZEREQWiz1CREREZkr//4eU8paOiRAREZGZ0klcNSalbH3BRIiIiMhM6QRIfPt89bXFXHGOEBEREVksJkJERERmSl8Nhyl0Oh2mTp0KHx8f2NnZ4fHHH8eMGTMg3LH6TBAExMXFoWnTprCzs0NISAjOnDljVE9+fj7CwsKgVCrh4uKCiIgI3Lp1yyjm119/RdeuXWFrawsvLy/MnTu3Qnu2bNmCtm3bwtbWFgEBAfj2229NfCImQkRERGZLDxl0Eg49ZCbdb86cOVixYgWWLl2K06dPY86cOZg7dy6WLFkixsydOxeJiYlISkrC4cOH4eDggNDQUBQXF4sxYWFhOHnyJNLS0pCSkoL9+/fj7bffFq9rNBr07NkT3t7eyMzMxLx58xAfH49PPvlEjElPT8frr7+OiIgI/Pzzz+jbty/69u2LEydOmPRMMkHgJgJ1jUajgbOzM2781hJKJ+aqVD+FegbWdhOIakSZUIq9+BqFhYVQKpU1cg/D74ljp9zhKOH3xK2benT0z6t0W1955RW4u7tj9erV4rkBAwbAzs4On332GQRBgKenJ8aOHYtx48YBAAoLC+Hu7o7k5GQMHjwYp0+fhr+/P3766Sd06tQJAJCamoqXX34Zly5dgqenJ1asWIEPPvgAarUaCoUCADBp0iRs27YN2dnZAIBBgwahqKgIKSkpYls6d+6MwMBAJCUlVfpnwN+yREREZkovSD+A8sTqzqOkpOSe93vmmWewe/du/PbbbwCAX375BQcOHMBLL70EADh//jzUajVCQkLEMs7OzggODkZGRgYAICMjAy4uLmISBAAhISGQy+U4fPiwGNOtWzcxCQKA0NBQ5OTk4MaNG2LMnfcxxBjuU1lcNUZERGSmDENcUsoDgJeXl9H5adOmIT4+vkL8pEmToNFo0LZtW1hZWUGn0+Gjjz5CWFgYAECtVgMA3N3djcq5u7uL19RqNdzc3IyuW1tbo1GjRkYxPj4+FeowXGvYsCHUavUD71NZTISIiIgs3MWLF42GxmxsbO4Zt3nzZqxfvx4bNmzAE088gaysLERHR8PT0xPh4eGPqrnViokQERGRmaquHiGlUlmpOULjx4/HpEmTMHjwYABAQEAA/vjjDyQkJCA8PBweHh4AgLy8PDRt2lQsl5eXh8DAQACAh4cHrl69alRvWVkZ8vPzxfIeHh7Iy8szijF8fliM4XplcY4QERGRmdILMsmHKf7++2/I5capg5WVFfT68oX4Pj4+8PDwwO7du8XrGo0Ghw8fhkqlAgCoVCoUFBQgMzNTjNmzZw/0ej2Cg4PFmP3796O0tFSMSUtLQ5s2bdCwYUMx5s77GGIM96ksJkJERERUKa+++io++ugj7NixAxcuXMDWrVuxYMEC9OvXDwAgk8kQHR2NmTNn4ptvvsHx48fx1ltvwdPTE3379gUA+Pn5oVevXhg5ciSOHDmCgwcPIioqCoMHD4anpycA4I033oBCoUBERAROnjyJTZs2YfHixYiNjRXbMmbMGKSmpmL+/PnIzs5GfHw8jh49iqioKJOeiUNjREREZqq6hsYqa8mSJZg6dSreeecdXL16FZ6envjPf/6DuLg4MWbChAkoKirC22+/jYKCAjz77LNITU2Fra2tGLN+/XpERUWhR48ekMvlGDBgABITE8Xrzs7O2LVrFyIjIxEUFITGjRsjLi7OaK+hZ555Bhs2bMCUKVPw/vvvo1WrVti2bRvatWtn0jNxH6E6iPsIkSXgPkJUXz3KfYT2nPCSvI/QC+0u1mhb6zr2CBEREZkpoQrzfO4ub+nY3UBEREQWiz1CREREZupRzxGqj5gIERERmSmdIIdOqPrgjo6zhDk0RkRERJaLPUJERERmSg8Z9BL6NPRglxATISIiIjPFOULScWiMiIiILBZ7hIiIiMyU9MnSHBpjIkRERGSmyucIVX14S0rZ+oJDY0RERGSx2CNERERkpvSQQ8dVY5IwESIiIjJTnCMkHRMhIiIiM6WHnPsIScQ5QkRERGSx2CNERERkpnSCDDpBwoaKEsrWF0yEiIiIzJRO4mRpHYfGODRGRERElos9QkRERGZKL8ihl7BqTM9VY0yEiIiIzBWHxqTj0BgRERFZLPYIERERmSk9pK380ldfU8wWEyEiIiIzJX1DRQ4M8SdAREREFos9QkRERGZK+rvG2B/CRIiIiMhM6SGDHlLmCHFnaSZCREREZoo9QtLxJ0BEREQWiz1CREREZkr6horsD2EiREREZKb0ggx6KfsI8e3zTAWJiIjIcrFHiIiIyEzpJQ6NcUNFJkJERERmS/rb55kI8SdAREREldKiRQvIZLIKR2RkJACguLgYkZGRcHV1haOjIwYMGIC8vDyjOnJzc9G7d2/Y29vDzc0N48ePR1lZmVHM3r170bFjR9jY2MDX1xfJyckV2rJs2TK0aNECtra2CA4OxpEjR6r0TEyEiIiIzJQOMsmHKX766SdcuXJFPNLS0gAA//73vwEAMTEx2L59O7Zs2YJ9+/bh8uXL6N+//z/t1enQu3dvaLVapKenY926dUhOTkZcXJwYc/78efTu3Rvdu3dHVlYWoqOjMWLECOzcuVOM2bRpE2JjYzFt2jQcO3YMHTp0QGhoKK5evWryz1AmCIJgcimqURqNBs7OzrjxW0sonZirUv0U6hlY200gqhFlQin24msUFhZCqVTWyD0Mvyc+PBwCW8eqz3IpvlWGacHf4+LFi0ZttbGxgY2NzUPLR0dHIyUlBWfOnIFGo0GTJk2wYcMGDBw4EACQnZ0NPz8/ZGRkoHPnzvjuu+/wyiuv4PLly3B3dwcAJCUlYeLEibh27RoUCgUmTpyIHTt24MSJE+J9Bg8ejIKCAqSmpgIAgoOD8dRTT2Hp0qUAAL1eDy8vL7z77ruYNGmSST8D/pYlIiKycF5eXnB2dhaPhISEh5bRarX47LPPMHz4cMhkMmRmZqK0tBQhISFiTNu2bdG8eXNkZGQAADIyMhAQECAmQQAQGhoKjUaDkydPijF31mGIMdSh1WqRmZlpFCOXyxESEiLGmIKTpYmIiMyUDjB5eOvu8gDu2SP0MNu2bUNBQQGGDh0KAFCr1VAoFHBxcTGKc3d3h1qtFmPuTIIM1w3XHhSj0Whw+/Zt3LhxAzqd7p4x2dnZD2333ZgIERERmanqWjWmVCpNHsZbvXo1XnrpJXh6elb5/nUBEyEiIiIzVVsvXf3jjz/w/fff46uvvhLPeXh4QKvVoqCgwKhXKC8vDx4eHmLM3au7DKvK7oy5e6VZXl4elEol7OzsYGVlBSsrq3vGGOowBecIERERkUnWrl0LNzc39O7dWzwXFBSEBg0aYPfu3eK5nJwc5ObmQqVSAQBUKhWOHz9utLorLS0NSqUS/v7+YsyddRhiDHUoFAoEBQUZxej1euzevVuMMQV7hIiIiMyUABn0EuYICVUoq9frsXbtWoSHh8Pa+p80wtnZGREREYiNjUWjRo2gVCrx7rvvQqVSoXPnzgCAnj17wt/fH0OGDMHcuXOhVqsxZcoUREZGivOSRo0ahaVLl2LChAkYPnw49uzZg82bN2PHjh3ivWJjYxEeHo5OnTrh6aefxqJFi1BUVIRhw4aZ/DxMhIiIiMxUbQyNff/998jNzcXw4cMrXFu4cCHkcjkGDBiAkpIShIaGYvny5eJ1KysrpKSkYPTo0VCpVHBwcEB4eDimT58uxvj4+GDHjh2IiYnB4sWL0axZM6xatQqhoaFizKBBg3Dt2jXExcVBrVYjMDAQqampFSZQVwb3EaqDuI8QWQLuI0T11aPcR2h8em/YODaocj0lt0ox75kdNdrWuo49QkRERGZKL8igF6o+NCalbH3BRIiIiMhM6SS+fV5K2fqCPwEiIiKyWOwRIiIiMlMcGpOOiRAREZGZ0kMOvYTBHSll6wv+BIiIiMhisUeIiIjITOkEGXQShreklK0vmAgRERGZKc4Rko6JEBERkZkSJL59XpBQtr7gT4CIiIgsFnuEiIiIzJQOMugkvHRVStn6gokQERGRmdIL0ub56Pm2UQ6NERERkeVijxCZHZ0O+Gy+B3Z/2RA3rjWAq3spXnwtH29E50H2//8w+ji6OdI2NzIqF/S8BrM2/A4AUF9UYMNCd2QddBTreKH/Dbw+Jg8NFBX/ifTneQUie7aB3Ar4Kvu4eP7b9Y3w/ZZG+CPHFgDgG3AbwyZfQdsn/66hpye6tzfHqjFkbJ7RuYtnbTCiW9u7IgXM/Ow8nnrhJuKHt0BGqvOjayRVO73EydJSytYXTIQegeTkZERHR6OgoKC2m1IvbF7mhpR1jTFucS682xTjzC92mB/THA5OOvQd8ZcY16m7BmMX5oqf70xwLp61gV4PjJlzCZ4+JbiQbYtF471Q/Lccb0+7bHS/slJg9jst0C64CKeOOhhd+zXdEd373oB/p7/RwEaPzcvc8P7rj+OTH7LRuGlpDf0EiO7tQrYtJg1qKX7W6SoOmfQb+RcEDofUG3rIoJcwz0dK2fqiVlPBoUOHQiaTYfbs2Ubnt23bBplM2n+c5ORkyGSyCseqVask1Uu179RRB6hCCxEcooGHlxZdXylEx+duIifL3iiugUJAI7cy8XBy0YnXnup+E+MWXUTQ8zfR1FsLVagGA0ddxcHvKv7rOHlOU3j5FqPbqwUVrk1alotXh17H4+1uo3mrEsTMvwhBD/x8wLHan5voYXQ64Ma1BuKhyTf+t27LJ25jwH+uYUGsVy21kKjuqfU+MVtbW8yZMwc3btyo9rqVSiWuXLlidISFhVWI02q11X5vqjn+nYqQdcAJl87ZAADOnbTFySMOeOqFm0Zxv2Y44rWAJxDxbFskTmoGTb7VA+stumlllCwBQNYBR/yY4oLIWZcq1baS23KUlckq1EP0KDzmo8WGYyeRnHEaE5f+gSaP/fN3m42dHpOW/YFlHzyGG9ca1GIrqToZdpaWcli6Wk+EQkJC4OHhgYSEhAfGffnll3jiiSdgY2ODFi1aYP78+Q+tWyaTwcPDw+iws7NDfHw8AgMDsWrVKvj4+MDWtnx+R2pqKp599lm4uLjA1dUVr7zyCs6dOyfWt3fvXshkMqMhrqysLMhkMly4cEE8l5ycjObNm8Pe3h79+vXD9evXTfuh0AMNirqK5/rcwIhubfFy8w6I7NkG/UZewwv9/0mmOz2vwfjFf2DO5nOI+OAKjmc44oM3W0J3n/zkz/MKfL2mCV4e8s/QmibfCh9HN8e4RblwcNJXqm2rP/KEq3spOna9+fBgomqUfcweH0d74YOwllgy6TF4NNdi/tazsHMo/9L/J/5PnDrqgIydnBNUnxjmCEk5LF2tzxGysrLCrFmz8MYbb+C9995Ds2bNKsRkZmbitddeQ3x8PAYNGoT09HS88847cHV1xdChQ6t037Nnz+LLL7/EV199BSur8p6CoqIixMbGon379rh16xbi4uLQr18/ZGVlQS6v3Jfl8OHDiIiIQEJCAvr27YvU1FRMmzbtgWVKSkpQUlIiftZoNFV6Jkux/xsX7PmqISYt+wPebYpx7qQdkqY99v+TpsuToef7FojxPn7F8PG/jaEqf/ya7ognu94yqu+vKw3wQdjj6PZKAV4OyxfPLxrvhe79biCgc1Gl2rVpiRv2fu2CeV+chcKWkzDo0Tr6g1L88/nTdsj+2QH/O3IK3f5VgMLr1gjscgvv9Gxdiy0kqptqPRECgH79+iEwMBDTpk3D6tWrK1xfsGABevTogalTpwIAWrdujVOnTmHevHkPTIQKCwvh6PjPXA1HR0eo1WoA5cNhn376KZo0aSJeHzBggFH5NWvWoEmTJjh16hTatWtXqWdZvHgxevXqhQkTJohtTU9PR2pq6n3LJCQk4MMPP6xU/QSsnOGJQVFXxWTHx68YVy8psHGJu5gI3a2ptxbOjcpw+YKNUSJ0XW2NCf9+HP6dijBm3kWjMlkHnZCxyxlfJLmVnxAAvV6Gl7w6IHruRYS+/k/StGVFE2xa5o7Zm86ipX9x9T4wURUUaaxw6XcbeLbQwqdtMZq20OKr7BNGMVNXXsCJww6YMNC3llpJUukh8V1jnCxdNxIhAJgzZw5eeOEFjBs3rsK106dPo0+fPkbnunTpgkWLFkGn04k9OndzcnLCsWPHxM939up4e3sbJUEAcObMGcTFxeHw4cP466+/oNeXD4fk5uZWOhE6ffo0+vXrZ3ROpVI9MBGaPHkyYmNjxc8ajQZeXpzMeD8lxXLI5MY9LnIr4YErYa5dbgDNDSs0cvtnJddfVxpgwr8fR6uA2xi7MBd3d/ot2v4b9Hesuknf6Ywty9yw8JszcPX4p57Ny9zweaI7Zm04h9Ydbkt7OKJqYmuvg6e3Fru/tMb+b1zw3Qbj7SQ++eE3/DfeE4d2Ke9TA5kDQeKqMYGJUN1JhLp164bQ0FBMnjy5ysNdd5PL5fD1vfe/dBwcHCqce/XVV+Ht7Y2VK1fC09MTer0e7dq1EydTGxIp4Y7fuKWl0pdI29jYwMbGRnI9lqLzixpsTHSH22Ol5UNjJ+zw1X/d0HNw+Vys20VyfDbfA8/2LkBDtzJcuaDAqpme8PQpQdDz5XN3/rrSAOMH+sLtMS1Gxl1G4fV//ldo5FYGAGjeqsTovr/9Yg+ZHGjR9p8en01L3fC/jz0wcdkfcPfSIv9qeT12DnrYOVRuXhFRdRgZdxmHdilx9ZICrh6lGDJODZ0e2Lu1IQrzre85QfrqnwrkXeTfPeaMb5+Xrs4kQgAwe/ZsBAYGok2bNkbn/fz8cPDgQaNzBw8eROvWre/bG2Sq69evIycnBytXrkTXrl0BAAcOHDCKMfQgXblyBQ0bNgRQPln67rYePnzY6NyhQ4eqpY1U7p2Zl7BublMsndwMBdet4epeipeH/IWwmPLN5ORyAedP2yJtiw+KNFZwdS9Dx+c0CJ+ghsKmPIk9tt8Jl8/b4PJ5G4QFPWFU/87LWZVuy45PG6NUK8fMkT5G59+MVWPIOLW0ByUyQeOmpZi8/A84NdSh8Lo1Tv7kgOhXWqEwv079NU9U59Sp/0MCAgIQFhaGxMREo/Njx47FU089hRkzZmDQoEHIyMjA0qVLsXz58mq7d8OGDeHq6opPPvkETZs2RW5uLiZNmmQU4+vrCy8vL8THx+Ojjz7Cb7/9VmH12nvvvYcuXbrg448/Rp8+fbBz584HDouR6ewd9Rg9/U+Mnv7nPa/b2AmY9fnvD6yj56B89ByU/8CYypT59Mgpk+ogqikJo71Nig/17FBDLaFHiTtLS1fnfgLTp08X5+YYdOzYEZs3b8bGjRvRrl07xMXFYfr06dU2hAaUD3tt3LgRmZmZaNeuHWJiYjBv3jyjmAYNGuDzzz9HdnY22rdvjzlz5mDmzJlGMZ07d8bKlSuxePFidOjQAbt27cKUKVOqrZ1EREQGhqExKYelkwkCN1uvazQaDZydnXHjt5ZQOtW5XJWoWoR6BtZ2E4hqRJlQir34GoWFhVAqa2YyuuH3RJ9dw9HAQVHlekqLtPi655oabWtdV6eGxoiIiKjy+K4x6ZgIERERmSmuGpOO4y5ERERksdgjREREZKbYIyQdEyEiIiIzxURIOg6NERERkcViIkRERGSmamMfoT///BNvvvkmXF1dYWdnh4CAABw9elS8LggC4uLi0LRpU9jZ2SEkJARnzpwxqiM/Px9hYWFQKpVwcXFBREQEbt26ZRTz66+/omvXrrC1tYWXlxfmzp1boS1btmxB27ZtYWtri4CAAHz77bcmPw8TISIiIjMl4J8l9FU5TN1I8MaNG+jSpQsaNGiA7777DqdOncL8+fPF104BwNy5c5GYmIikpCQcPnwYDg4OCA0NRXHxP+9pDAsLw8mTJ5GWloaUlBTs378fb7/9tnhdo9GgZ8+e8Pb2RmZmJubNm4f4+Hh88sknYkx6ejpef/11RERE4Oeff0bfvn3Rt29fnDhxwqRn4oaKdRA3VCRLwA0Vqb56lBsqvrBjFKwdqv7i3LKiEuzpnVTptk6aNAkHDx7Ejz/+eM/rgiDA09MTY8eOxbhx4wAAhYWFcHd3R3JyMgYPHozTp0/D398fP/30Ezp16gQASE1Nxcsvv4xLly7B09MTK1aswAcffAC1Wg2FQiHee9u2bcjOzgYADBo0CEVFRUhJSRHv37lzZwQGBiIpKanSPwP+liUiIrJwGo3G6CgpKbln3DfffINOnTrh3//+N9zc3PDkk09i5cqV4vXz589DrVYjJCREPOfs7Izg4GBkZGQAADIyMuDi4iImQQAQEhICuVwuvrQ8IyMD3bp1E5MgAAgNDUVOTg5u3Lghxtx5H0OM4T6VxUSIiIjITFXXHCEvLy84OzuLR0JCwj3v9/vvv2PFihVo1aoVdu7cidGjR+O9997DunXrAABqtRoA4O7ublTO3d1dvKZWq+Hm5mZ03draGo0aNTKKuVcdd97jfjGG65XF5fNERERmqrqWz1+8eNFoaMzG5t7DbXq9Hp06dcKsWbMAAE8++SROnDiBpKQkhIeHV7kdtYk9QkRERBZOqVQaHfdLhJo2bQp/f3+jc35+fsjNzQUAeHh4AADy8vKMYvLy8sRrHh4euHr1qtH1srIy5OfnG8Xcq44773G/GMP1ymIiREREZKYe9fL5Ll26ICcnx+jcb7/9Bm9vbwCAj48PPDw8sHv3bvG6RqPB4cOHoVKpAAAqlQoFBQXIzMwUY/bs2QO9Xo/g4GAxZv/+/SgtLRVj0tLS0KZNG3GFmkqlMrqPIcZwn8piIkRERGSmBEEm+TBFTEwMDh06hFmzZuHs2bPYsGEDPvnkE0RGRgIAZDIZoqOjMXPmTHzzzTc4fvw43nrrLXh6eqJv374AynuQevXqhZEjR+LIkSM4ePAgoqKiMHjwYHh6egIA3njjDSgUCkRERODkyZPYtGkTFi9ejNjYWLEtY8aMQWpqKubPn4/s7GzEx8fj6NGjiIqKMumZOEeIiIiIKuWpp57C1q1bMXnyZEyfPh0+Pj5YtGgRwsLCxJgJEyagqKgIb7/9NgoKCvDss88iNTUVtra2Ysz69esRFRWFHj16QC6XY8CAAUhMTBSvOzs7Y9euXYiMjERQUBAaN26MuLg4o72GnnnmGWzYsAFTpkzB+++/j1atWmHbtm1o166dSc/EfYTqIO4jRJaA+whRffUo9xFSff2u5H2EMvosqdG21nXsESIiIjJTfOmqdOxuICIiIovFHiEiIiIzVZUJz3eXt3RMhIiIiMwUh8akYyJERERkptgjJB3nCBEREZHFYo8QERGRmRIkDo2xR4iJEBERkdkSAEjZDZAbCXJojIiIiCwYe4SIiIjMlB4yyCBh1ZiEsvUFEyEiIiIzxVVj0nFojIiIiCwWe4SIiIjMlF6QQcYNFSVhIkRERGSmBEHiqjEuG+PQGBEREVku9ggRERGZKU6Wlo6JEBERkZliIiQdEyEiIiIzxcnS0nGOEBEREVks9ggRERGZKa4ak46JEBERkZkqT4SkzBGqxsaYKQ6NERERkcVijxAREZGZ4qox6ZgIERERmSnh/w8p5S0dh8aIiIjIYrFHiIiIyExxaEw6JkJERETmimNjkjERIiIiMlcSe4TAHiHOESIiIiLLxR4hIiIiM8WdpaVjIkRERGSmOFlaOg6NERERkcViIkRERGSuBJn0wwTx8fGQyWRGR9u2bcXrxcXFiIyMhKurKxwdHTFgwADk5eUZ1ZGbm4vevXvD3t4ebm5uGD9+PMrKyoxi9u7di44dO8LGxga+vr5ITk6u0JZly5ahRYsWsLW1RXBwMI4cOWLSsxgwESIiIjJThjlCUg5TPfHEE7hy5Yp4HDhwQLwWExOD7du3Y8uWLdi3bx8uX76M/v37i9d1Oh169+4NrVaL9PR0rFu3DsnJyYiLixNjzp8/j969e6N79+7IyspCdHQ0RowYgZ07d4oxmzZtQmxsLKZNm4Zjx46hQ4cOCA0NxdWrV01+HiZCREREVGnW1tbw8PAQj8aNGwMACgsLsXr1aixYsAAvvPACgoKCsHbtWqSnp+PQoUMAgF27duHUqVP47LPPEBgYiJdeegkzZszAsmXLoNVqAQBJSUnw8fHB/Pnz4efnh6ioKAwcOBALFy4U27BgwQKMHDkSw4YNg7+/P5KSkmBvb481a9aY/DxMhIiIiMyVUA0HAI1GY3SUlJTc95ZnzpyBp6cnWrZsibCwMOTm5gIAMjMzUVpaipCQEDG2bdu2aN68OTIyMgAAGRkZCAgIgLu7uxgTGhoKjUaDkydPijF31mGIMdSh1WqRmZlpFCOXyxESEiLGmIKJEBERkZkyrBqTcgCAl5cXnJ2dxSMhIeGe9wsODkZycjJSU1OxYsUKnD9/Hl27dsXNmzehVquhUCjg4uJiVMbd3R1qtRoAoFarjZIgw3XDtQfFaDQa3L59G3/99Rd0Ot09Ywx1mKJSy+e/+eabSlf4r3/9y+RGEBERUe25ePEilEql+NnGxuaecS+99JL45/bt2yM4OBje3t7YvHkz7OzsarydNaFSiVDfvn0rVZlMJoNOp5PSHiIiIjJFNWyKqFQqjRKhynJxcUHr1q1x9uxZvPjii9BqtSgoKDDqFcrLy4OHhwcAwMPDo8LqLsOqsjtj7l5plpeXB6VSCTs7O1hZWcHKyuqeMYY6TFGpoTG9Xl+pg0kQERHRo1NdQ2NVdevWLZw7dw5NmzZFUFAQGjRogN27d4vXc3JykJubC5VKBQBQqVQ4fvy40equtLQ0KJVK+Pv7izF31mGIMdShUCgQFBRkFKPX67F7924xxhSS5ggVFxdLKU5ERERSVNNk6coaN24c9u3bhwsXLiA9PR39+vWDlZUVXn/9dTg7OyMiIgKxsbH44YcfkJmZiWHDhkGlUqFz584AgJ49e8Lf3x9DhgzBL7/8gp07d2LKlCmIjIwUh+NGjRqF33//HRMmTEB2djaWL1+OzZs3IyYmRmxHbGwsVq5ciXXr1uH06dMYPXo0ioqKMGzYMJN/hCa/YkOn02HWrFlISkpCXl4efvvtN7Rs2RJTp05FixYtEBERYXIjiIiIqO67dOkSXn/9dVy/fh1NmjTBs88+i0OHDqFJkyYAgIULF0Iul2PAgAEoKSlBaGgoli9fLpa3srJCSkoKRo8eDZVKBQcHB4SHh2P69OlijI+PD3bs2IGYmBgsXrwYzZo1w6pVqxAaGirGDBo0CNeuXUNcXBzUajUCAwORmppaYQJ1ZcgEwbTtlKZPn45169Zh+vTpGDlyJE6cOIGWLVti06ZNWLRoUZWWrpExjUYDZ2dn3PitJZROXNhH9VOoZ2BtN4GoRpQJpdiLr1FYWFileTeVYfg94ZUUD7mdbZXr0d8uxsVR8TXa1rrO5N+yn376KT755BOEhYXByspKPN+hQwdkZ2dXa+OIiIjoAR7x0Fh9ZHIi9Oeff8LX17fCeb1ej9LS0mppFBEREdGjYHIi5O/vjx9//LHC+S+++AJPPvlktTSKiIiIKoE9QpKZPFk6Li4O4eHh+PPPP6HX6/HVV18hJycHn376KVJSUmqijURERHQvVXiDfIXyFs7kHqE+ffpg+/bt+P777+Hg4IC4uDicPn0a27dvx4svvlgTbSQiIiKqESb3CAFA165dkZaWVt1tISIiIhMIQvkhpbylq1IiBABHjx7F6dOnAZTPGwoKCqq2RhEREVElSJ3nw0TI9ETIsJnSwYMHxXeJFBQU4JlnnsHGjRvRrFmz6m4jERERUY0weY7QiBEjUFpaitOnTyM/Px/5+fk4ffo09Ho9RowYURNtJCIionsxTJaWclg4k3uE9u3bh/T0dLRp00Y816ZNGyxZsgRdu3at1sYRERHR/cmE8kNKeUtnciLk5eV1z40TdTodPD09q6VRREREVAmcIySZyUNj8+bNw7vvvoujR4+K544ePYoxY8bg448/rtbGEREREdWkSvUINWzYEDLZP+OIRUVFCA4OhrV1efGysjJYW1tj+PDh6Nu3b400lIiIiO7CDRUlq1QitGjRohpuBhEREZmMQ2OSVSoRCg8Pr+l2EBERET1yVd5QEQCKi4uh1WqNzimVSkkNIiIiokpij5BkJk+WLioqQlRUFNzc3ODg4ICGDRsaHURERPSI8O3zkpmcCE2YMAF79uzBihUrYGNjg1WrVuHDDz+Ep6cnPv3005poIxEREVGNMHlobPv27fj000/x/PPPY9iwYejatSt8fX3h7e2N9evXIywsrCbaSURERHfjqjHJTO4Rys/PR8uWLQGUzwfKz88HADz77LPYv39/9baOiIiI7suws7SUw9KZnAi1bNkS58+fBwC0bdsWmzdvBlDeU2R4CSsRERGROTA5ERo2bBh++eUXAMCkSZOwbNky2NraIiYmBuPHj6/2BhIREdF9cLK0ZCbPEYqJiRH/HBISguzsbGRmZsLX1xft27ev1sYRERER1SRJ+wgBgLe3N7y9vaujLURERGQCGSS+fb7aWmK+KpUIJSYmVrrC9957r8qNISIiInqUKpUILVy4sFKVyWQyJkLVqF/rAFjLGtR2M4iIqK7i8nnJKpUIGVaJERERUR3CV2xIZvKqMSIiIqL6QvJkaSIiIqol7BGSjIkQERGRmZK6OzR3lubQGBEREVkw9ggRERGZKw6NSValHqEff/wRb775JlQqFf78808AwP/+9z8cOHCgWhtHRERED8BXbEhmciL05ZdfIjQ0FHZ2dvj5559RUlICACgsLMSsWbOqvYFERERUN82ePRsymQzR0dHiueLiYkRGRsLV1RWOjo4YMGAA8vLyjMrl5uaid+/esLe3h5ubG8aPH4+ysjKjmL1796Jjx46wsbGBr68vkpOTK9x/2bJlaNGiBWxtbREcHIwjR46Y/AwmJ0IzZ85EUlISVq5ciQYN/tnsr0uXLjh27JjJDSAiIqKqMUyWlnJU1U8//YT//ve/Fd4zGhMTg+3bt2PLli3Yt28fLl++jP79+4vXdTodevfuDa1Wi/T0dKxbtw7JycmIi4sTY86fP4/evXuje/fuyMrKQnR0NEaMGIGdO3eKMZs2bUJsbCymTZuGY8eOoUOHDggNDcXVq1dNeg6TE6GcnBx069atwnlnZ2cUFBSYWh0RERFVlWFnaSkHAI1GY3QYRnvu59atWwgLC8PKlSvRsGFD8XxhYSFWr16NBQsW4IUXXkBQUBDWrl2L9PR0HDp0CACwa9cunDp1Cp999hkCAwPx0ksvYcaMGVi2bBm0Wi0AICkpCT4+Ppg/fz78/PwQFRWFgQMHGr3pYsGCBRg5ciSGDRsGf39/JCUlwd7eHmvWrDHpR2hyIuTh4YGzZ89WOH/gwAG0bNnS1OqIiIioqqppjpCXlxecnZ3FIyEh4YG3jYyMRO/evRESEmJ0PjMzE6WlpUbn27Zti+bNmyMjIwMAkJGRgYCAALi7u4sxoaGh0Gg0OHnypBhzd92hoaFiHVqtFpmZmUYxcrkcISEhYkxlmbxqbOTIkRgzZgzWrFkDmUyGy5cvIyMjA+PGjcPUqVNNrY6IiIhq2cWLF6FUKsXPNjY2943duHEjjh07hp9++qnCNbVaDYVCARcXF6Pz7u7uUKvVYsydSZDhuuHag2I0Gg1u376NGzduQKfT3TMmOzv7IU9rzOREaNKkSdDr9ejRowf+/vtvdOvWDTY2Nhg3bhzeffddU6sjIiKiKqquDRWVSqVRInQ/Fy9exJgxY5CWlgZbW9uq37gOMXloTCaT4YMPPkB+fj5OnDiBQ4cO4dq1a5gxY0ZNtI+IiIju5xEvn8/MzMTVq1fRsWNHWFtbw9raGvv27UNiYiKsra3h7u4OrVZbYc5wXl4ePDw8AJRPsbl7FZnh88NilEol7Ozs0LhxY1hZWd0zxlBHZVV5Z2mFQgF/f388/fTTcHR0rGo1REREZCZ69OiB48ePIysrSzw6deqEsLAw8c8NGjTA7t27xTI5OTnIzc2FSqUCAKhUKhw/ftxodVdaWhqUSiX8/f3FmDvrMMQY6lAoFAgKCjKK0ev12L17txhTWSYPjXXv3h0ymey+1/fs2WNqlURERFQVEofGTO0RcnJyQrt27YzOOTg4wNXVVTwfERGB2NhYNGrUCEqlEu+++y5UKhU6d+4MAOjZsyf8/f0xZMgQzJ07F2q1GlOmTEFkZKQ4N2nUqFFYunQpJkyYgOHDh2PPnj3YvHkzduzYId43NjYW4eHh6NSpE55++mksWrQIRUVFGDZsmEnPZHIiFBgYaPS5tLQUWVlZOHHiBMLDw02tjoiIiKqqDr5iY+HChZDL5RgwYABKSkoQGhqK5cuXi9etrKyQkpKC0aNHQ6VSwcHBAeHh4Zg+fboY4+Pjgx07diAmJgaLFy9Gs2bNsGrVKoSGhooxgwYNwrVr1xAXFwe1Wo3AwECkpqZWmED9MDJBEKrlxxAfH49bt27h448/ro7qLJpGo4GzszOeRx9Yyxo8vAAREdUZZUIp9uJrFBYWVmoCclUYfk+0nDILVhImLeuKi/H7zPdrtK11XbW9ff7NN980eRMjIiIikoDvGpOs2t4+n5GRUW+W0hEREZmD6lo+b8lMToTufF8IAAiCgCtXruDo0aPcUJGIiIjMismJkLOzs9FnuVyONm3aYPr06ejZs2e1NYyIiIioppmUCOl0OgwbNgwBAQFGL1kjIiKiWlAHV42ZG5MmS1tZWaFnz558yzwREVEdYJgjJOWwdCavGmvXrh1+//33mmgLERER0SNlciI0c+ZMjBs3DikpKbhy5Qo0Go3RQURERI8Ql85LUuk5QtOnT8fYsWPx8ssvAwD+9a9/Gb1qQxAEyGQy6HS66m8lERERVcQ5QpJVOhH68MMPMWrUKPzwww812R4iIiKiR6bSiZDhTRzPPfdcjTWGiIiIKo8bKkpn0vL5B711noiIiB4xDo1JZlIi1Lp164cmQ/n5+ZIaRERERPSomJQIffjhhxV2liYiIqLawaEx6UxKhAYPHgw3N7eaagsRERGZgkNjklV6HyHODyIiIqL6xuRVY0RERFRHsEdIskonQnq9vibbQURERCbiHCHpTJojRERERHUIe4QkM/ldY0RERET1BXuEiIiIzBV7hCRjIkRERGSmOEdIOg6NERERkcVijxAREZG54tCYZEyEiIiIzBSHxqTj0BgRERFZLPYIERERmSsOjUnGRIiIiMhcMRGSjENjREREZLHYI0RERGSmZP9/SClv6ZgIERERmSsOjUnGRIiIiMhMcfm8dJwjRERERJWyYsUKtG/fHkqlEkqlEiqVCt999514vbi4GJGRkXB1dYWjoyMGDBiAvLw8ozpyc3PRu3dv2Nvbw83NDePHj0dZWZlRzN69e9GxY0fY2NjA19cXycnJFdqybNkytGjRAra2tggODsaRI0eq9ExMhIiIiMyVUA2HCZo1a4bZs2cjMzMTR48exQsvvIA+ffrg5MmTAICYmBhs374dW7Zswb59+3D58mX0799fLK/T6dC7d29otVqkp6dj3bp1SE5ORlxcnBhz/vx59O7dG927d0dWVhaio6MxYsQI7Ny5U4zZtGkTYmNjMW3aNBw7dgwdOnRAaGgorl69atoDAZAJgsCOsTpGo9HA2dkZz6MPrGUNars5RERkgjKhFHvxNQoLC6FUKmvkHobfE0/8ZxasFLZVrkenLcbJ/74vqa2NGjXCvHnzMHDgQDRp0gQbNmzAwIEDAQDZ2dnw8/NDRkYGOnfujO+++w6vvPIKLl++DHd3dwBAUlISJk6ciGvXrkGhUGDixInYsWMHTpw4Id5j8ODBKCgoQGpqKgAgODgYTz31FJYuXQoA0Ov18PLywrvvvotJkyaZ1H72CBEREVk4jUZjdJSUlDy0jE6nw8aNG1FUVASVSoXMzEyUlpYiJCREjGnbti2aN2+OjIwMAEBGRgYCAgLEJAgAQkNDodFoxF6ljIwMozoMMYY6tFotMjMzjWLkcjlCQkLEGFMwESIiIjJThsnSUg4A8PLygrOzs3gkJCTc957Hjx+Ho6MjbGxsMGrUKGzduhX+/v5Qq9VQKBRwcXExind3d4darQYAqNVqoyTIcN1w7UExGo0Gt2/fxl9//QWdTnfPGEMdpuCqMSIiInNVTcvnL168aDQ0ZmNjc98ibdq0QVZWFgoLC/HFF18gPDwc+/btk9CI2sVEiIiIyMIZVoFVhkKhgK+vLwAgKCgIP/30ExYvXoxBgwZBq9WioKDAqFcoLy8PHh4eAAAPD48Kq7sMq8rujLl7pVleXh6USiXs7OxgZWUFKyure8YY6jAFh8aIiIjMVHUNjUmh1+tRUlKCoKAgNGjQALt37xav5eTkIDc3FyqVCgCgUqlw/Phxo9VdaWlpUCqV8Pf3F2PurMMQY6hDoVAgKCjIKEav12P37t1ijCnYI0RERGSuHvHO0pMnT8ZLL72E5s2b4+bNm9iwYQP27t2LnTt3wtnZGREREYiNjUWjRo2gVCrx7rvvQqVSoXPnzgCAnj17wt/fH0OGDMHcuXOhVqsxZcoUREZGisNxo0aNwtKlSzFhwgQMHz4ce/bswebNm7Fjxw6xHbGxsQgPD0enTp3w9NNPY9GiRSgqKsKwYcNM/hEwESIiIqJKuXr1Kt566y1cuXIFzs7OaN++PXbu3IkXX3wRALBw4ULI5XIMGDAAJSUlCA0NxfLly8XyVlZWSElJwejRo6FSqeDg4IDw8HBMnz5djPHx8cGOHTsQExODxYsXo1mzZli1ahVCQ0PFmEGDBuHatWuIi4uDWq1GYGAgUlNTK0ygrgzuI1QHcR8hIiLz9Sj3EWo/XPo+Qr+ukbaPkLljjxAREZG54ktXJWMiREREZK6YCEnGVWNERERksdgjREREZKakLoGvjuXz5o6JEBERkbni0JhkHBojIiIii8UeISIiIjMlEwTIJOyCI6VsfcFEiIiIyFxxaEwyDo0RERGRxWKPEBERkZniqjHpmAgRERGZKw6NScahMSIiIrJY7BEiIiIyUxwak46JEBERkbni0JhkTISIiIjMFHuEpOMcISIiIrJY7BEiIiIyVxwak4yJEBERkRnj8JY0HBojIiIii8UeISIiInMlCOWHlPIWjokQERGRmeKqMek4NEZEREQWiz1CRERE5oqrxiRjIkRERGSmZPryQ0p5S8ehMSIiIrJY7BEiizAoKg9dXi6El28JtMVynDpqj9UfNcWlc7ZizNwvzqLDM0VG5XZ86orESc0edXOJHqpd8C38+51raBXwN1w9yhA/vAUyUp0BAFbWAoZOvIKnXriJpt5aFGnk+PlHJ6ye1RT5eQ0AAO7NtHgjJg+BXW6hYZNSXM9rgD1fNcTni91QVsp/I5sNDo1JxkSohg0dOhQFBQXYtm1bbTfForVXFWF7cmP8lmVf/kti0hXM+vx3jHyuDUpuW4lx337WCJ/O8xA/l9zmLwSqm2zt9fj9pC12ft4I09ZcMLpmY6eHb8BtbFjkjt9P2cLRWYfR0y/jw+TzePel1gAAL99iyOUCFk9shsvnFWjRthjR8y7B1l6PldM9a+GJqCq4aky6epsIDR06FOvWratw/syZM/D19a2FFlFt+iCspdHn+dHNsfnESbRqfxsnDjuK50tuy3HjWoNH3Twikx39QYmjPyjvee3vm1aYPPhxo3PLPngMS747gyaPaXHtTwWO7lXi6N5/yqtzbfDF4yV45a3rTITMCfcRkqzeJkIA0KtXL6xdu9boXJMmTYw+a7VaKBSKR9ksqgMclDoAwM0CK6Pz3fvfwAsDbuDG1QY4lKbEhkXu7BWiesFBqYNeDxQVWt0/xklX4f8JovquXv8Nb2NjAw8PD6OjR48eiIqKQnR0NBo3bozQ0FAAwIIFCxAQEAAHBwd4eXnhnXfewa1bt8S64uPjERgYaFT/okWL0KJFC/GzTqdDbGwsXFxc4OrqigkTJkCoRLZdUlICjUZjdFDNkckEjPrwT5w4Yo8/cuzE8z9sbYi5Uc0xYeDj2LjEDT0G3MCEJbm12FKi6tHARo+ID65g7zYX/H3r3omOZ4sS9Bn+F779n+sjbh1JYRgak3JYunqdCN3PunXroFAocPDgQSQlJQEA5HI5EhMTcfLkSaxbtw579uzBhAkTTKp3/vz5SE5Oxpo1a3DgwAHk5+dj69atDy2XkJAAZ2dn8fDy8qrSc1HlRM36E95ti5Ew2tvo/HfrXZG5T4kL2Xb4YWtDzBvjhWdfLkRT75JaaimRdFbWAj747x+ADFhyn4n/rh6l+Gj979if4oLvNjARMitCNRwWrl4PjaWkpMDR8Z/5Hy+99BIAoFWrVpg7d65RbHR0tPjnFi1aYObMmRg1ahSWL19e6fstWrQIkydPRv/+/QEASUlJ2Llz50PLTZ48GbGxseJnjUbDZKiGRH50CcEvajC23+P468qDh0Szj9kDKP+X8pU/bB5F84iqVXkSdAHuj2kx4bXH79kb1Mi9FHO3nMWpow5YPJ4rJMny1Oseoe7duyMrK0s8EhMTAQBBQUEVYr///nv06NEDjz32GJycnDBkyBBcv34df//9d6XuVVhYiCtXriA4OFg8Z21tjU6dOj20rI2NDZRKpdFB1U1A5EeX8EyvQkz49+PIu/jwxObxdsUAgPyrnDxN5seQBD3mo8WkQY/j5o2K/+519SjFvC/O4sxxe8yP8YIgyGqhpSTFox4aS0hIwFNPPQUnJye4ubmhb9++yMnJMYopLi5GZGQkXF1d4ejoiAEDBiAvL88oJjc3F71794a9vT3c3Nwwfvx4lJWVGcXs3bsXHTt2hI2NDXx9fZGcnFyhPcuWLUOLFi1ga2uL4OBgHDlyxLQHQj1PhBwcHODr6yseTZs2Fc/f6cKFC3jllVfQvn17fPnll8jMzMSyZcsAlE+mBsqHzu6e71NaWvoInoKqQ9SsP/FC/xuYHemN27fkaNikFA2blEJhW76talPvErwRnQffgL/h3kyLzj0LMX5xLn7NcMD503YPqZ3o0bO116HlE7fR8onbAAAPLy1aPnEbTR7TwspawNSVF9C6w23MiWoOuZUgfuetG5R/5w1J0LXLCqyc7gln1zIxhsyIYdWYlMME+/btQ2RkJA4dOoS0tDSUlpaiZ8+eKCr6Zw+2mJgYbN++HVu2bMG+fftw+fJlcaQEKJ9P27t3b2i1WqSnp2PdunVITk5GXFycGHP+/Hn07t1b7NCIjo7GiBEjjEZZNm3ahNjYWEybNg3Hjh1Dhw4dEBoaiqtXr5r0TPV6aKyyMjMzodfrMX/+fMjl5bnh5s2bjWKaNGkCtVoNQRAgk5X/qykrK0u87uzsjKZNm+Lw4cPo1q0bAKCsrAyZmZno2LHjo3kQuq9Xh14HAHz81Tmj8x9HeyFtcyOUlcrwZNeb6DfiGmzt9bh2uQEOfOuMzxe510ZziR6qdYfbmPflP9/nUR9eBgDs2tQQn833gCq0fNHFiu9/Myo3fsDj+DXDER273cRjLbV4rKUWG46dMooJ9exQw60nc5Wammr0OTk5GW5ubsjMzES3bt1QWFiI1atXY8OGDXjhhRcAAGvXroWfnx8OHTqEzp07Y9euXTh16hS+//57uLu7IzAwEDNmzMDEiRMRHx8PhUKBpKQk+Pj4YP78+QAAPz8/HDhwAAsXLjRa5DRy5EgMGzYMQPl0lB07dmDNmjWYNGlSpZ+JiRAAX19flJaWYsmSJXj11VeNJlEbPP/887h27Rrmzp2LgQMHIjU1Fd99953RMNaYMWMwe/ZstGrVCm3btsWCBQtQUFDwiJ+G7uVhf7Ffu6zA+AHcX4rMx68Zjg/8Xj/sO5+2uRHSNjeq7mbRI1ZdGyrevVrZxsYGNjYPn0JQWFgIAGjUqPy7lJmZidLSUoSEhIgxbdu2RfPmzZGRkYHOnTsjIyMDAQEBcHf/5x+aoaGhGD16NE6ePIknn3wSGRkZRnUYYgzzebVaLTIzMzF58mTxulwuR0hICDIyMir/A0A9HxqrrA4dOmDBggWYM2cO2rVrh/Xr1yMhIcEoxs/PD8uXL8eyZcvQoUMHHDlyBOPGjTOKGTt2LIYMGYLw8HCoVCo4OTmhX79+j/JRiIjIklTTqjEvLy+j1ct3/w68F71ej+joaHTp0gXt2rUDAKjVaigUCri4uBjFuru7Q61WizF3JkGG64ZrD4rRaDS4ffs2/vrrL+h0unvGGOqorHrbI3SvSVVA+eSre4mJiUFMTIzRuSFDhhh9HjVqFEaNGmV07v333xf/bG1tjUWLFmHRokUmt5eIiKi2XLx40WiEozK9QZGRkThx4gQOHDhQk02rcfU2ESIiIqrvqmtozNQVy1FRUUhJScH+/fvRrNk/2y54eHhAq9WioKDAqFcoLy8PHh4eYszdq7sMq8rujLl7pVleXh6USiXs7OxgZWUFKyure8YY6qgsDo0RERGZK70g/TCBIAiIiorC1q1bsWfPHvj4+BhdDwoKQoMGDbB7927xXE5ODnJzc6FSqQAAKpUKx48fN1rdlZaWBqVSCX9/fzHmzjoMMYY6FAoFgoKCjGL0ej12794txlQWe4SIiIjMldTdoU0sGxkZiQ0bNuDrr7+Gk5OTOB/H2dkZdnZ2cHZ2RkREBGJjY9GoUSMolUq8++67UKlU6Ny5MwCgZ8+e8Pf3x5AhQzB37lyo1WpMmTIFkZGR4pDcqFGjsHTpUkyYMAHDhw/Hnj17sHnzZuzYsUNsS2xsLMLDw9GpUyc8/fTTWLRoEYqKisRVZJXFRIiIiIgqZcWKFQDKV1Lfae3atRg6dCgAYOHChZDL5RgwYABKSkoQGhpq9JYGKysrpKSkYPTo0VCpVHBwcEB4eDimT58uxvj4+GDHjh2IiYnB4sWL0axZM6xatUpcOg8AgwYNwrVr1xAXFwe1Wo3AwECkpqZWmED9MDKhMm8FpUdKo9HA2dkZz6MPrGXc1ZiIyJyUCaXYi69RWFhYY28KMPye6BLyIaytbatcT1lZMQ5+P61G21rXsUeIiIjIXFVhd+gK5S0cJ0sTERGRxWKPEBERkZmqruXzloyJEBERkbl6xKvG6iMOjREREZHFYo8QERGRmZIJAmQSJjxLKVtfMBEiIiIyV/r/P6SUt3AcGiMiIiKLxR4hIiIiM8WhMemYCBEREZkrrhqTjIkQERGRueLO0pJxjhARERFZLPYIERERmSnuLC0dEyEiIiJzxaExyTg0RkRERBaLPUJERERmSqYvP6SUt3RMhIiIiMwVh8Yk49AYERERWSz2CBEREZkrbqgoGRMhIiIiM8VXbEjHoTEiIiKyWOwRIiIiMlecLC0ZEyEiIiJzJQCQsgSeeRATISIiInPFOULScY4QERERWSz2CBEREZkrARLnCFVbS8wWEyEiIiJzxcnSknFojIiIiCwWe4SIiIjMlR6ATGJ5C8dEiIiIyExx1Zh0HBojIiIii8UeISIiInPFydKSMREiIiIyV0yEJOPQGBEREVXa/v378eqrr8LT0xMymQzbtm0zui4IAuLi4tC0aVPY2dkhJCQEZ86cMYrJz89HWFgYlEolXFxcEBERgVu3bhnF/Prrr+jatStsbW3h5eWFuXPnVmjLli1b0LZtW9ja2iIgIADffvutyc/DRIiIiMhcGXqEpBwmKioqQocOHbBs2bJ7Xp87dy4SExORlJSEw4cPw8HBAaGhoSguLhZjwsLCcPLkSaSlpSElJQX79+/H22+/LV7XaDTo2bMnvL29kZmZiXnz5iE+Ph6ffPKJGJOeno7XX38dERER+Pnnn9G3b1/07dsXJ06cMOl5ZILAfrG6RqPRwNnZGc+jD6xlDWq7OUREZIIyoRR78TUKCwuhVCpr5B6G3xM92oyFtZVNlesp05Vgd858XLx40aitNjY2sLF5eL0ymQxbt25F3759AZT3Bnl6emLs2LEYN24cAKCwsBDu7u5ITk7G4MGDcfr0afj7++Onn35Cp06dAACpqal4+eWXcenSJXh6emLFihX44IMPoFaroVAoAACTJk3Ctm3bkJ2dDQAYNGgQioqKkJKSIranc+fOCAwMRFJSUqV/BuwRIiIiMlOG5fNSDgDw8vKCs7OzeCQkJFSpPefPn4darUZISIh4ztnZGcHBwcjIyAAAZGRkwMXFRUyCACAkJARyuRyHDx8WY7p16yYmQQAQGhqKnJwc3LhxQ4y58z6GGMN9KouTpYmIiCzcvXqEqkKtVgMA3N3djc67u7uL19RqNdzc3IyuW1tbo1GjRkYxPj4+FeowXGvYsCHUavUD71NZTISIiIjMVTWtGlMqlTU2jFfXcWiMiIjIXOkF6Uc18vDwAADk5eUZnc/LyxOveXh44OrVq0bXy8rKkJ+fbxRzrzruvMf9YgzXK4uJEBEREVULHx8feHh4YPfu3eI5jUaDw4cPQ6VSAQBUKhUKCgqQmZkpxuzZswd6vR7BwcFizP79+1FaWirGpKWloU2bNmjYsKEYc+d9DDGG+1QWEyEiIiJzVQvL52/duoWsrCxkZWUBKJ8gnZWVhdzcXMhkMkRHR2PmzJn45ptvcPz4cbz11lvw9PQUV5b5+fmhV69eGDlyJI4cOYKDBw8iKioKgwcPhqenJwDgjTfegEKhQEREBE6ePIlNmzZh8eLFiI2NFdsxZswYpKamYv78+cjOzkZ8fDyOHj2KqKgok56Hc4SIiIjMlsQ5QjC97NGjR9G9e3fxsyE5CQ8PR3JyMiZMmICioiK8/fbbKCgowLPPPovU1FTY2tqKZdavX4+oqCj06NEDcrkcAwYMQGJionjd2dkZu3btQmRkJIKCgtC4cWPExcUZ7TX0zDPPYMOGDZgyZQref/99tGrVCtu2bUO7du1Meh7uI1QHcR8hIiLz9Sj3EQpp+R6s5RL2EdKX4PvfE2u0rXUde4SIiIjMFd81JhkTISIiInOlF1CV4S3j8paNk6WJiIjIYrFHiIiIyFwJ+vJDSnkLx0SIiIjIXHGOkGRMhIiIiMwV5whJxjlCREREZLHYI0RERGSuODQmGRMhIiIicyVAYiJUbS0xWxwaIyIiIovFHiEiIiJzxaExyZgIERERmSu9HoCEvYD03EeIQ2NERERksdgjREREZK44NCYZEyEiIiJzxURIMg6NERERkcVijxAREZG54is2JGMiREREZKYEQQ9BwhvkpZStL5gIERERmStBkNarwzlCnCNERERElos9QkREROZKkDhHiD1CTISIiIjMll4PyCTM8+EcIQ6NERERkeVijxAREZG54tCYZEyEiIiIzJSg10OQMDTG5fMcGiMiIiILxh4hIiIic8WhMcmYCBEREZkrvQDImAhJwaExIiIisljsESIiIjJXggBAyj5C7BFiIkRERGSmBL0AQcLQmMBEiIkQERGR2RL0kNYjxOXznCNEREREFos9QkRERGaKQ2PSMREiIiIyVxwak4yJUB1kyNDLUCppnywiInr0ylAK4NH0tkj9PWFoqyVjIlQH3bx5EwBwAN/WckuIiKiqbt68CWdn5xqpW6FQwMPDAwfU0n9PeHh4QKFQVEOrzJNM4ABhnaPX63H58mU4OTlBJpPVdnPqPY1GAy8vL1y8eBFKpbK2m0NU7fgdf7QEQcDNmzfh6ekJubzm1iQVFxdDq9VKrkehUMDW1rYaWmSe2CNUB8nlcjRr1qy2m2FxlEolf0lQvcbv+KNTUz1Bd7K1tbXoBKa6cPk8ERERWSwmQkRERGSxmAiRxbOxscG0adNgY2NT200hqhH8jhPdHydLExERkcVijxARERFZLCZCREREZLGYCBEREZHFYiJEVAuSk5Ph4uJS280gqrShQ4eib9++td0MomrHRIjqlKFDh0Imk2H27NlG57dt2yZ5l+3k5GTIZLIKx6pVqyTVS1STDP9P3H2cPXu2tptGVC9wZ2mqc2xtbTFnzhz85z//QcOGDau1bqVSiZycHKNz99oBVqvVWvS7d6hu6dWrF9auXWt0rkmTJkaf+Z0lqhr2CFGdExISAg8PDyQkJDww7ssvv8QTTzwBGxsbtGjRAvPnz39o3TKZDB4eHkaHnZ0d4uPjERgYiFWrVsHHx0fctj41NRXPPvssXFxc4OrqildeeQXnzp0T69u7dy9kMhkKCgrEc1lZWZDJZLhw4YJ4Ljk5Gc2bN4e9vT369euH69evm/ZDIYtmY2NT4Xvbo0cPREVFITo6Go0bN0ZoaCgAYMGCBQgICICDgwO8vLzwzjvv4NatW2Jdhu/6nRYtWoQWLVqIn3U6HWJjY8Xv/YQJEx7Jm9SJagMTIapzrKysMGvWLCxZsgSXLl26Z0xmZiZee+01DB48GMePH0d8fDymTp2K5OTkKt/37Nmz+PLLL/HVV18hKysLAFBUVITY2FgcPXoUu3fvhlwuR79+/aDX6ytd7+HDhxEREYGoqChkZWWhe/fumDlzZpXbSWSwbt06KBQKHDx4EElJSQDK31WYmJiIkydPYt26ddizZw8mTJhgUr3z589HcnIy1qxZgwMHDiA/Px9bt26tiUcgqnUcGqM6qV+/fggMDMS0adOwevXqCtcXLFiAHj16YOrUqQCA1q1b49SpU5g3bx6GDh1633oLCwvh6OgofnZ0dIRarQZQPrTw6aefGg05DBgwwKj8mjVr0KRJE5w6dQrt2rWr1LMsXrwYvXr1En8ZtW7dGunp6UhNTa1UeaKUlBSj7+1LL70EAGjVqhXmzp1rFBsdHS3+uUWLFpg5cyZGjRqF5cuXV/p+ixYtwuTJk9G/f38AQFJSEnbu3CnhCYjqLvYIUZ01Z84crFu3DqdPn65w7fTp0+jSpYvRuS5duuDMmTPQ6XT3rdPJyQlZWVnikZ6eLl7z9vauMO/izJkzeP3119GyZUsolUpx+CA3N7fSz3H69GkEBwcbnVOpVJUuT9S9e3ej721iYiIAICgoqELs999/jx49euCxxx6Dk5MThgwZguvXr+Pvv/+u1L0KCwtx5coVo++stbU1OnXqVD0PQ1THsEeI6qxu3bohNDQUkydPfmAvjynkcjl8fX3vec3BwaHCuVdffRXe3t5YuXIlPD09odfr0a5dO2i1WrE+AEbzJ0pLS6ulrUQGDg4O9/ze3v2dvXDhAl555RWMHj0aH330ERo1aoQDBw4gIiICWq0W9vb2kMvlFeb78DtLlow9QlSnzZ49G9u3b0dGRobReT8/Pxw8eNDo3MGDB9G6dWtYWVlVy72vX7+OnJwcTJkyBT169ICfnx9u3LhhFGPoQbpy5Yp4zjC/6M62Hj582OjcoUOHqqWNRHfKzMyEXq/H/Pnz0blzZ7Ru3RqXL182imnSpAnUarVRMnTnd9bZ2RlNmzY1+s6WlZUhMzOzxttPVBvYI0R1WkBAAMLCwsShAIOxY8fiqaeewowZMzBo0CBkZGRg6dKlJs2DeJiGDRvC1dUVn3zyCZo2bYrc3FxMmjTJKMbX1xdeXl6Ij4/HRx99hN9++63C6rX33nsPXbp0wccff4w+ffpg586dnB9ENcLX1xelpaVYsmQJXn31VaNJ1AbPP/88rl27hrlz52LgwIFITU3Fd999B6VSKcaMGTMGs2fPRqtWrdC2bVssWLDAaGUkUX3CHiGq86ZPn15hlVbHjh2xefNmbNy4Ee3atUNcXBymT59ebUNoQPmw18aNG5GZmYl27dohJiYG8+bNM4pp0KABPv/8c2RnZ6N9+/aYM2dOhRVhnTt3xsqVK7F48WJ06NABu3btwpQpU6qtnUQGHTp0wIIFCzBnzhy0a9cO69evr7ANhZ+fH5YvX45ly5ahQ4cOOHLkCMaNG2cUM3bsWAwZMgTh4eFQqVRwcnJCv379HuWjED0yMoGbQxAREZGFYo8QERERWSwmQkRERGSxmAgRERGRxWIiRERERBaLiRARERFZLCZCREREZLGYCBEREZHFYiJEREREFouJEBHd09ChQ9G3b1/x8/PPP4/o6OhH3o69e/dCJpM98BUPMpkM27Ztq3Sd8fHxCAwMlNSuCxcuQCaTVXi3HBGZFyZCRGZk6NChkMlkkMlkUCgU8PX1xfTp01FWVlbj9/7qq68wY8aMSsVWJnkhIqoL+NJVIjPTq1cvrF27FiUlJfj2228RGRmJBg0aYPLkyRVitVotFApFtdy3UaNG1VIPEVFdwh4hIjNjY2MDDw8PeHt7Y/To0QgJCcE333wD4J/hrI8++gienp5o06YNAODixYt47bXX4OLigkaNGqFPnz64cOGCWKdOp0NsbCxcXFzg6uqKCRMm4O7XEN49NFZSUoKJEyfCy8sLNjY28PX1xerVq3HhwgV0794dANCwYUPIZDLxZbh6vR4JCQnw8fGBnZ0dOnTogC+++MLoPt9++y1at24NOzs7dO/e3aidlTVx4kS0bt0a9vb2aNmyJaZOnYrS0tIKcf/973/h5eUFe3t7vPbaaygsLDS6vmrVKvj5+cHW1hZt27bF8uXLTW4LEdVtTISIzJydnR20Wq34effu3cjJyUFaWhpSUlJQWlqK0NBQODk54ccff8TBgwfh6OiIXr16ieXmz5+P5ORkrFmzBgcOHEB+fj62bt36wPu+9dZb+Pzzz5GYmIjTp0/jv//9LxwdHeHl5YUvv/wSAJCTk4MrV65g8eLFAICEhAR8+umnSEpKwsmTJxETE4M333wT+/btA1CesPXv3x+vvvoqsrKyMGLECEyaNMnkn4mTkxOSk5Nx6tQpLF68GCtXrsTChQuNYs6ePYvNmzdj+/btSE1Nxc8//4x33nlHvL5+/XrExcXho48+wunTpzFr1ixMnToV69atM7k9RFSHCURkNsLDw4U+ffoIgiAIer1eSEtLE2xsbIRx48aJ193d3YWSkhKxzP/+9z+hTZs2gl6vF8+VlJQIdnZ2ws6dOwVBEISmTZsKc+fOFa+XlpYKzZo1E+8lCILw3HPPCWPGjBEEQRBycnIEAEJaWto92/nDDz8IAIQbN26I54qLiwV7e3shPT3dKDYiIkJ4/fXXBUEQhMmTJwv+/v5G1ydOnFihrrsBELZu3Xrf6/PmzROCgoLEz9OmTROsrKyES5cuiee+++47QS6XC1euXBEEQRAef/xxYcOGDUb1zJgxQ1CpVIIgCML58+cFAMLPP/983/sSUd3HOUJEZiYlJQWOjo4oLS2FXq/HG2+8gfj4ePF6QECA0bygX375BWfPnoWTk5NRPcXFxTh37hwKCwtx5coVBAcHi9esra3RqVOnCsNjBllZWbCyssJzzz1X6XafPXsWf//9N1588UWj81qtFk8++SQA4PTp00btAACVSlXpexhs2rQJiYmJOHfuHG7duoWysjIolUqjmObNm+Oxxx4zuo9er0dOTg6cnJxw7tw5REREYOTIkWJMWVkZnJ2dTW4PEdVdTISIzEz37t2xYsUKKBQKeHp6wtra+H9jBwcHo8+3bt1CUFAQ1q9fX6GuJk2aVKkNdnZ2Jpe5desWAGDHjh1GCQhQPu+pumRkZCAsLAwffvghQkND4ezsjI0bN2L+/Pkmt3XlypUVEjMrK6tqaysR1T4mQkRmxsHBAb6+vpWO79ixIzZt2gQ3N7cKvSIGTZs2xeHDh9GtWzcA5T0fmZmZ6Nix4z3jAwICoNfrsW/fPoSEhFS4buiR0ul04jl/f3/Y2NggNzf3vj1Jfn5+4sRvg0OHDj38Ie+Qnp4Ob29vfPDBB+K5P/74o0Jcbm4uLl++DE9PT/E+crkcbdq0gbu7Ozw9PfH7778jLCzMpPsTkXnhZGmiei4sLAyNGzdGnz598OOPP+L8+fPYu3cv3nvvPVy6dAkAMGbMGMyePRvbtm1DdnY23nnnnQfuAdSiRQuEh4dj+PDh2LZtm1jn5s2bAQDe3t6QyWRISUnBtWvXcOvWLTg5OWHcuHGIiYnBunXrcO7cORw7dgxLliwRJyCPGjUKZ86cwfjx45GTk4MNGzYgOTnZpOdt1aoVcnNzsXHjRpw7dw6JiYn3nPhta2uL8PBw/PLLL/jxxx/x3nvv4bXXXoOHhwcA4MMPP0RCQgISExPx22+/4fjx41i7di0WLFhgUnuIqG5jIkRUz9nb22P//v1o3rw5+vfvDz8/P0RERKC4uFjsIRo7diyGDBmC8PBwqFQqODk5oV+/fg+sd8WKFRg4cCDeeecdtG3bFiNHjkRRUREA4LHHHsOHH36ISZMmwd3dHVFRUQCAGTNmYOrUqUhISICfnx969eqFHTt2wMfHB0D5vJ0vv/wS27ZtQ4cOHZCUlIRZs2aZ9Lz/+te/EBMTg6ioKAQGBiI9PR1Tp06tEOfr64v+/fvj5ZdfRs+ePdG+fXuj5fEjRozAqlWrsHbtWgQEBOC5555DcnKy2FYiqh9kwv1mQxIRERHVc+wRIiIiIovFRIiIiIgsFhMhIiIislhMhIiIiMhiMREiIiIii8VEiIiIiCwWEyEiIiKyWEyEiIiIyGIxESIiIiKLxUSIiIiILBYTISIiIrJY/wfo+Y26mLEOOQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "smote_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(smote_matrix, display_labels=['No Fraud', 'Fraud'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
